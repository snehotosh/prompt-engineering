{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d0609d",
   "metadata": {},
   "source": [
    "## A Comprehensive Guide on various types of `prompting methods` using `Langchain` - `PART1`\n",
    "* `@author: Snehotosh Banerjee`\n",
    "* `Date of creation: 03-05-2023`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad0e7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "899d2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain modules\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33961915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0696b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"text-davinci-003\", ## model to be used\n",
    "    temperature=0.7,          ## (controls randomness) Less is more deterministic, more is more random\n",
    "    max_tokens=256,           ## \n",
    "    top_p=1,                  ## the “top p” parameter is like a filter that controls how many different words or phrases \n",
    "                              ## the language model considers when it’s trying to predict the next word.\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(params, prompt):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine = params['model'],\n",
    "        prompt = prompt,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa61bc",
   "metadata": {},
   "source": [
    "### Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32666422",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = set_open_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c0cf014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "The Prime Minister of India is Narendra Modi."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who is the PM of India\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "response.choices[0].text\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f835d72",
   "metadata": {},
   "source": [
    "### Text Summarization Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e18624be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Due to their distinct characteristics, airplanes and helicopters have different capabilities that make helicopters more useful in certain situations such as search and rescue missions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"summarize this text in one sentence\"\n",
    "prompt = f\"{instruction}: Because of the differences in the way the aircraft fly, there are also differences in what they’re able to do. An airplane is more limited than a helicopter in its abilities and will not be able to do all the things that make a helicopter so cool and useful. For example, an airplane needs a long runway in order to take off while a helicopter can take off by lifting straight up. This means that a helicopter is able to go places that an airplane can’t because it will be able to get out again without a long runway. Helicopters are able to land in many places that would otherwise be inaccessible, which makes them very useful in search and rescue missions.\"\n",
    "\n",
    "response = get_completion(params, extra_prompt)\n",
    "response.choices[0].text\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1ed08",
   "metadata": {},
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "574381d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       ", but service was a bit slow\n",
       "\n",
       "Neutral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Classify the text into neutral, negative or positive.\"\n",
    "prompt = f\"{instruction}: I think food was good\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "response.choices[0].text\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b585a8",
   "metadata": {},
   "source": [
    "### Query Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9816b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "Table departments, columns = [DepartmentId, DepartmentName]\n",
      "Table students, columns = [DepartmentId, StudentId, StudentName]\n",
      "Create a MySQL query for all students in the Computer Science Department\n",
      "\"\"\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "SELECT StudentId, StudentName\n",
       "FROM students\n",
       "WHERE DepartmentId = (SELECT DepartmentId FROM departments WHERE DepartmentName = 'Computer Science');"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
    "\n",
    "print(prompt)\n",
    "response = get_completion(params, prompt)\n",
    "response.choices[0].text\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07068818",
   "metadata": {},
   "source": [
    "### LLMs and External Tools with Agents\n",
    "\n",
    "* Used `LLM` models and `Google Search API` as tool\n",
    "* Used agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "717c1ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9851189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f81258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e42587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should research this question.\n",
      "Action: Search\n",
      "Action Input: \"Jock Zonfrillo cause of death\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mEXCLUSIVE: Inside the secret health battle Jock Zonfrillo has been fighting behind closed doors for years - after the MasterChef star's sudden death at 46 shocked the TV world. MasterChef judge Jock Zonfrillo secretly battled bowel cancer for years, sources have said.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This article suggests that Jock Zonfrillo's cause of death was bowel cancer.\n",
      "Final Answer: Jock Zonfrillo's cause of death was bowel cancer.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Jock Zonfrillo's cause of death was bowel cancer.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Do you know the cause of death of Jock Zonfrillo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a3bc8",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65e6754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a06985a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Respond in one short sentence\"\n",
    "template = f\"{instruction}:\" + \"I really want to travel to {location}. What should I do there?\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"location\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43eed5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prompt: Respond in one short sentence:I really want to travel to Rome. What should I do there?\n",
      "LLM Output: \n",
      "\n",
      "Explore the city's historical sites, monuments, and museums.\n"
     ]
    }
   ],
   "source": [
    "final_prompt = prompt.format(location='Rome')\n",
    "\n",
    "print (f\"Final Prompt: {final_prompt}\")\n",
    "print (f\"LLM Output: {llm(final_prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69057f85",
   "metadata": {},
   "source": [
    "### Chaining\n",
    "\n",
    "* Simple Chaining\n",
    "* Using agents\n",
    "* Add state to chains and agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629cf853",
   "metadata": {},
   "source": [
    "#### Simple Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb57f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a639e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f32669f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "983132dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France - for the world-famous pastries and desserts, such as éclairs and tarts. \n",
      "2. New York City, USA - for classic American desserts like cheesecake and cookies. \n",
      "3. Tokyo, Japan - for traditional Japanese sweets such as mochi and warabimochi. \n",
      "4. Vienna, Austria - for the famous Sachertorte, a delicious chocolate cake. \n",
      "5. Barcelona, Spain - for churros and classic Spanish desserts like Crema Catalana.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"dessert\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d051fc",
   "metadata": {},
   "source": [
    "#### Memory chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6cd36438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9cce4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e164beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bba5ad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ebd3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You said \"Hi there!\"'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What was the first thing I said to you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60183a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:  You said \"Hi there!\"\n",
      "Human: what is an alternative phrase for the first thing I said to you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' An alternative phrase for the first thing you said to me could be \"Greetings!\"'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is an alternative phrase for the first thing I said to you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8144619",
   "metadata": {},
   "source": [
    "### Querying Tabular Data\n",
    "\n",
    "* `SQL` agent\n",
    "* `Pandas` agent\n",
    "* `CSV` agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93481ab1",
   "metadata": {},
   "source": [
    "#### Pandas Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "901de936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bf9dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08110479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3d2555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0) ## Making it utmost deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd678906",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(llm, df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c53cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to count the number of rows\n",
      "Action: python_repl_ast\n",
      "Action Input: df.shape[0]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m891\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 891 rows.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 891 rows.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Query\n",
    "'''\n",
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68cb6381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out the number of survivors for each gender\n",
      "Action: python_repl_ast\n",
      "Action Input: df.groupby('Sex')['Survived'].sum()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSex\n",
      "female    233\n",
      "male      109\n",
      "Name: Survived, dtype: int64\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Male survived least.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Male survived least.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Query\n",
    "'''\n",
    "agent.run(\"which gender survived least?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce614e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
